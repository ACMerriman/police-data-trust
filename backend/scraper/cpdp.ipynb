{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CPDP Data Into the NPDC Index\n",
    "\n",
    "This notebook processes the `unified_data` from [chicago-police-data](https://github.com/invinst/chicago-police-data/tree/master/data) and loads it into the NPDC index database.\n",
    "\n",
    "Data is only inserted once, so it's safe to run this multiple times.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install project dependencies and Jupyter:\n",
    "\n",
    "```bash\n",
    "pip3 install jupyter\n",
    "pip3 install -r requirements/dev_unix.txt\n",
    "```\n",
    "\n",
    "This notebook should be run from the repo root, and `unified_data_path` should point to the `unified_data` directory of the `chicago-police-data` repo.\n",
    "\n",
    "The database should be running and the tables should be up to date. You can use docker to reset the application to a clean state: \n",
    "\n",
    "```bash\n",
    "# Stop services and remove volumes, rebuild images, start the database, create tables, run seeds, and follow logs\n",
    "docker-compose down -v && docker-compose up --build -d db api && docker-compose logs -f\n",
    "```\n",
    "\n",
    "Then open the notebook with either [VSCode](https://code.visualstudio.com/) or `jupyter notebook`.\n",
    "\n",
    "You can run the notebook from the command line as well:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --to notebook --execute backend/scraper/cpdp.ipynb --output cpdp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:39.710816Z",
     "iopub.status.busy": "2021-11-09T18:09:39.710311Z",
     "iopub.status.idle": "2021-11-09T18:09:40.259016Z",
     "shell.execute_reply": "2021-11-09T18:09:40.259245Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().endswith(\"scraper\"):\n",
    "    # Run this notebook from the repo root\n",
    "    os.chdir(\"../..\")\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "from IPython.display import display, HTML\n",
    "from collections import namedtuple\n",
    "from backend.database import db, Incident, Officer, Accusation, Victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:40.262031Z",
     "iopub.status.busy": "2021-11-09T18:09:40.261697Z",
     "iopub.status.idle": "2021-11-09T18:09:40.357755Z",
     "shell.execute_reply": "2021-11-09T18:09:40.357465Z"
    }
   },
   "outputs": [],
   "source": [
    "from backend.api import create_app\n",
    "app = create_app(\"development\")\n",
    "\n",
    "unified_data_path = \"../chicago-police-data/data/unified_data\"\n",
    "if not os.path.exists(unified_data_path):\n",
    "    raise Exception(f\"{unified_data_path} does not exist. Working directory should be the police-data-trust repo root and cpdp repo should be checked out in a sibling directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data Files\n",
    "\n",
    "Data is organized into CSV's under `data/unified_data`. CSV file naming is described in `data/README.md`. CSV columns are described in `data/unified_data/data-dictionary/data-dictionary.yaml` as well as `data/complaints_general-summary.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:40.363648Z",
     "iopub.status.busy": "2021-11-09T18:09:40.363390Z",
     "iopub.status.idle": "2021-11-09T18:09:41.898808Z",
     "shell.execute_reply": "2021-11-09T18:09:41.898567Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_path(*args):\n",
    "    return os.path.join(unified_data_path, *args)\n",
    "\n",
    "\n",
    "def float_to_int_str(x):\n",
    "    \"\"\"Converts a floating-point string into an integer string.\n",
    "\n",
    "    Empty strings are converted to nan\n",
    "    \"\"\"\n",
    "    return str(int(float(x))) if x else math.nan\n",
    "\n",
    "\n",
    "def read_csv(*path):\n",
    "    return pd.read_csv(\n",
    "        data_path(*path),\n",
    "        dtype={\n",
    "            \"cr_id\": str,\n",
    "        },\n",
    "        converters={\n",
    "            \"link_UID\": float_to_int_str,\n",
    "            \"birth_year\": float_to_int_str,\n",
    "            \"investigator_ID\": float_to_int_str,\n",
    "            \"UID\": float_to_int_str,\n",
    "        },\n",
    "        low_memory=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def read_complaint(name):\n",
    "    return read_csv(\"complaints\", f\"complaints-{name}.csv.gz\")\n",
    "\n",
    "\n",
    "def check_defined(df, column):\n",
    "    assert df[column].isnull().values.sum() == 0\n",
    "\n",
    "\n",
    "# Each record is one complaint, primary key cr_id\n",
    "complaints = read_complaint(\"complaints\").set_index(\n",
    "    \"cr_id\", drop=False, verify_integrity=True\n",
    ")\n",
    "\n",
    "# Each record is an officer, deduplicated across data sources, primary key UID\n",
    "profiles = read_csv(\"profiles\", \"final-profiles.csv.gz\").set_index(\n",
    "    \"UID\", drop=False, verify_integrity=True\n",
    ")\n",
    "\n",
    "# Each record is an accusation against one officer in one complaint, composite\n",
    "# key (cr_id, UID)\n",
    "accused = read_complaint(\"accused\").set_index(\n",
    "    [\"cr_id\", \"UID\"], drop=False, verify_integrity=True\n",
    ")\n",
    "\n",
    "# Each record is a person that filed a complaint. Many-to-1 with cr_id\n",
    "complainants = read_complaint(\"complainants\")\n",
    "check_defined(complainants, \"cr_id\")\n",
    "\n",
    "# Each record is a person assigned to investigate a particular complaint.\n",
    "# Many-to-1 with (cr_id, investigator_ID). investigator_ID includes officer\n",
    "# UID's and non-officer investigators. The same investigator may be assigned to\n",
    "# the same complaint at different times, resulting in multiple records.\n",
    "investigators = read_complaint(\"investigators\")\n",
    "check_defined(investigators, [\"cr_id\", \"investigator_ID\"])\n",
    "\n",
    "# Each record is a victim in a complaint. Many-to-1 with cr_id. victims_v3\n",
    "# contains injury information which is lost in the merged victims table.\n",
    "victims_v2 = read_complaint(\"victims_2000-2016_2016-11\")\n",
    "victims_v3 = read_complaint(\"victims_2000-2018_2018-03\")\n",
    "victims_unified = read_complaint(\"victims\")\n",
    "check_defined(victims_v2, \"cr_id\")\n",
    "check_defined(victims_v3, \"cr_id\")\n",
    "check_defined(victims_unified, \"cr_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:41.904116Z",
     "iopub.status.busy": "2021-11-09T18:09:41.903867Z",
     "iopub.status.idle": "2021-11-09T18:09:41.906030Z",
     "shell.execute_reply": "2021-11-09T18:09:41.905775Z"
    }
   },
   "outputs": [],
   "source": [
    "def isnan(x):\n",
    "    return isinstance(x, float) and math.isnan(x)\n",
    "\n",
    "\n",
    "def nan_to_none(x):\n",
    "    return None if isnan(x) else x\n",
    "\n",
    "\n",
    "def strip_nan(r):\n",
    "    return r._make([nan_to_none(e) for e in r])\n",
    "\n",
    "\n",
    "def to_orm(instances, OrmClass):\n",
    "    return [\n",
    "        OrmClass(**strip_nan(i)._asdict())\n",
    "        for i in instances.itertuples(index=False)\n",
    "    ]\n",
    "\n",
    "\n",
    "def to_dicts(instances):\n",
    "    \"\"\"Converts dataframe rows into dicts, converting NaN to None\"\"\"\n",
    "    return [strip_nan(i)._asdict() for i in instances.itertuples(index=False)]\n",
    "\n",
    "\n",
    "def create_bulk(instances, chunk_size=1000):\n",
    "    \"\"\"Inserts ORM instances into the database\"\"\"\n",
    "    for chunk in range(0, len(instances), chunk_size):\n",
    "        db.session.add_all(instances[chunk : chunk + chunk_size])\n",
    "        db.session.flush()\n",
    "    db.session.commit()\n",
    "\n",
    "\n",
    "def insert_bulk(dicts, OrmClass):\n",
    "    \"\"\"Inserts dicts into the database.\n",
    "\n",
    "    This is 3x faster but does not implement ORM features.\n",
    "    \"\"\"\n",
    "    with app.app_context():\n",
    "        db.session.bulk_insert_mappings(OrmClass, dicts)\n",
    "        db.session.commit()\n",
    "\n",
    "\n",
    "def insert_bulk_if_missing(dicts, OrmClass):\n",
    "    try:\n",
    "        insert_bulk(dicts, OrmClass)\n",
    "    except sqlalchemy.exc.IntegrityError as e:\n",
    "        if isinstance(e.orig, psycopg2.errors.UniqueViolation):\n",
    "            print(f\"Already created {OrmClass.__name__} records\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "\n",
    "def add_date_of_birth(target, birth_year):\n",
    "    # Default to 01-01 for birthday\n",
    "    has_birth_year = ~birth_year.isna()\n",
    "    target.loc[has_birth_year, \"date_of_birth\"] = (\n",
    "        birth_year[has_birth_year] + \"-01-01\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:41.913603Z",
     "iopub.status.busy": "2021-11-09T18:09:41.909970Z",
     "iopub.status.idle": "2021-11-09T18:09:42.441719Z",
     "shell.execute_reply": "2021-11-09T18:09:42.441925Z"
    }
   },
   "outputs": [],
   "source": [
    "incidents = complaints[[\"complaint_date\", \"closed_date\"]].copy()\n",
    "incidents[\"source\"] = \"cpdp\"\n",
    "incidents[[\"source_id\", \"time_of_incident\"]] = complaints[\n",
    "    [\"cr_id\", \"incident_date\"]\n",
    "]\n",
    "has_full_address = ~complaints[\"full_address\"].isna()\n",
    "\n",
    "# full address only contains street information, so add the city\n",
    "incidents.loc[has_full_address, \"location\"] = (\n",
    "    complaints.loc[has_full_address, \"full_address\"] + \" CHICAGO ILLINOIS\"\n",
    ")\n",
    "\n",
    "# Join the address components, ignoring missing values and consolidating whitespace\n",
    "address = complaints[~has_full_address]\n",
    "incidents.loc[~has_full_address, \"location\"] = (\n",
    "    address[\"add1\"]\n",
    "    .str.cat(address[[\"add2\", \"city\"]], na_rep=\" \")\n",
    "    .str.strip()\n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    ")\n",
    "\n",
    "incident_dicts = to_dicts(incidents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:42.445025Z",
     "iopub.status.busy": "2021-11-09T18:09:42.444725Z",
     "iopub.status.idle": "2021-11-09T18:09:42.465044Z",
     "shell.execute_reply": "2021-11-09T18:09:42.464835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created Incident records\n"
     ]
    }
   ],
   "source": [
    "insert_bulk_if_missing(incident_dicts, Incident)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Officers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:42.469643Z",
     "iopub.status.busy": "2021-11-09T18:09:42.468505Z",
     "iopub.status.idle": "2021-11-09T18:09:42.590725Z",
     "shell.execute_reply": "2021-11-09T18:09:42.590930Z"
    }
   },
   "outputs": [],
   "source": [
    "officers = profiles[\n",
    "    [\"first_name\", \"last_name\", \"race\", \"gender\", \"appointed_date\"]\n",
    "].copy()\n",
    "officers[\"source\"] = \"cpdp\"\n",
    "officers[[\"source_id\", \"rank\", \"star\", \"unit\"]] = profiles[\n",
    "    [\n",
    "        \"link_UID\",\n",
    "        \"cleaned_rank\",\n",
    "        \"current_star\",\n",
    "        \"current_unit\",\n",
    "    ]\n",
    "]\n",
    "add_date_of_birth(officers, profiles[\"birth_year\"])\n",
    "\n",
    "officer_dicts = to_dicts(officers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:42.594150Z",
     "iopub.status.busy": "2021-11-09T18:09:42.593900Z",
     "iopub.status.idle": "2021-11-09T18:09:42.596716Z",
     "shell.execute_reply": "2021-11-09T18:09:42.596491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created Officer records\n"
     ]
    }
   ],
   "source": [
    "insert_bulk_if_missing(officer_dicts, Officer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Mapping from CPDP to NPDC ID's\n",
    "\n",
    "CPDP entities are linked together using incident and officer ID's. There is a 1-many corespondance between incidents/officers and victims, investigations, participants, and accusations. In order to insert these entities into the database, we need to convert the CPDP id's in the source data to their corresponding NPDC id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:42.599989Z",
     "iopub.status.busy": "2021-11-09T18:09:42.599694Z",
     "iopub.status.idle": "2021-11-09T18:09:43.054377Z",
     "shell.execute_reply": "2021-11-09T18:09:43.054113Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_source_npdc_id_map(OrmClass):\n",
    "    \"\"\"Returns a dict mapping non-null source ID's to NPDC id's (PK's)\"\"\"\n",
    "    with app.app_context():\n",
    "        ids = (\n",
    "            db.session.query(OrmClass)\n",
    "            .filter(OrmClass.source_id != None)\n",
    "            .with_entities(OrmClass.source_id, OrmClass.id)\n",
    "            .all()\n",
    "        )\n",
    "    return dict(ids)\n",
    "\n",
    "\n",
    "officer_id_by_link_uid = get_source_npdc_id_map(Officer)\n",
    "incident_id_by_cr_id = get_source_npdc_id_map(Incident)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Accusations\n",
    "\n",
    "Complaints may be made against multiple officers for a single incident. Each accusation links a single officer to a single incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:43.066310Z",
     "iopub.status.busy": "2021-11-09T18:09:43.065954Z",
     "iopub.status.idle": "2021-11-09T18:09:44.489037Z",
     "shell.execute_reply": "2021-11-09T18:09:44.488744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created Accusation records\n"
     ]
    }
   ],
   "source": [
    "accusations = pd.DataFrame()\n",
    "accusations[[\"category\", \"category_code\", \"finding\", \"outcome\"]] = accused[\n",
    "    [\"complaint_category\", \"complaint_code\", \"final_finding\", \"final_outcome\"]\n",
    "].copy()\n",
    "accusations[\"incident_id\"] = accused[\"cr_id\"].map(incident_id_by_cr_id)\n",
    "accusations[\"officer_id\"] = accused[\"link_UID\"].map(officer_id_by_link_uid)\n",
    "check_defined(accusations, [\"incident_id\", \"officer_id\"])\n",
    "\n",
    "insert_bulk_if_missing(to_dicts(accusations), Accusation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Officers by Number of Accusations\n",
    "\n",
    "This matches the results at [cpdp.co](https://cpdp.co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:44.494292Z",
     "iopub.status.busy": "2021-11-09T18:09:44.494026Z",
     "iopub.status.idle": "2021-11-09T18:09:44.725075Z",
     "shell.execute_reply": "2021-11-09T18:09:44.724750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      " SELECT officer.source_id AS officer_source_id, officer.first_name AS officer_first_name, officer.last_name AS officer_last_name, count(*) AS count_1 \n",
      "FROM officer JOIN accusation ON officer.id = accusation.officer_id GROUP BY officer.id ORDER BY count(*) DESC \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Officer Name</th>\n",
       "      <th>Number of Accusations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8562</th>\n",
       "      <td>Jerome Finnigan</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21837</th>\n",
       "      <td>Joe Parker</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17816</th>\n",
       "      <td>Edward May</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>Glenn Evans</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>Kevin Osborn</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28717</th>\n",
       "      <td>Richard Topel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>Robert Brown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15566</th>\n",
       "      <td>John Lahti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10854</th>\n",
       "      <td>John Grode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>Roy Chuskas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22813 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Officer Name  Number of Accusations\n",
       "id                                           \n",
       "8562   Jerome Finnigan                    175\n",
       "21837       Joe Parker                    137\n",
       "17816       Edward May                    136\n",
       "8138       Glenn Evans                    132\n",
       "21468     Kevin Osborn                    125\n",
       "...                ...                    ...\n",
       "28717    Richard Topel                      1\n",
       "3040      Robert Brown                      1\n",
       "15566       John Lahti                      1\n",
       "10854       John Grode                      1\n",
       "4625       Roy Chuskas                      1\n",
       "\n",
       "[22813 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desc = db.desc\n",
    "count = db.func.count\n",
    "with app.app_context():\n",
    "    q = (\n",
    "        db.session.query(\n",
    "            Officer.source_id, Officer.first_name, Officer.last_name, count()\n",
    "        )\n",
    "        .join(Accusation)\n",
    "        .group_by(Officer.id)\n",
    "        .order_by(desc(count()))\n",
    "    )\n",
    "    print(\"Query:\\n\", str(q), \"\\n\")\n",
    "    df = pd.DataFrame(\n",
    "        data=[\n",
    "            (id, f\"{first.title()} {last.title()}\", num_accusations)\n",
    "            for id, first, last, num_accusations in q\n",
    "        ],\n",
    "        columns=[\"id\", \"Officer Name\", \"Number of Accusations\"],\n",
    "    ).set_index(\"id\")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Victims\n",
    "\n",
    "Victims may or may not be the person making the complaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T18:09:44.746235Z",
     "iopub.status.busy": "2021-11-09T18:09:44.735725Z",
     "iopub.status.idle": "2021-11-09T18:09:45.149585Z",
     "shell.execute_reply": "2021-11-09T18:09:45.149824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created Victim records\n"
     ]
    }
   ],
   "source": [
    "# About 25% of victims reference cr_id which is missing in the complaints table.\n",
    "# CPDP still shows information for these complaints, and I'm not sure where that\n",
    "# data comes from. For our purposes, drop victims with no associated complaint.\n",
    "# Ex https://cpdp.co/complaint/1086131/\n",
    "victims_v2 = victims_v2[victims_v2.cr_id.isin(incident_id_by_cr_id)]\n",
    "victims_v3 = victims_v3[victims_v3.cr_id.isin(incident_id_by_cr_id)]\n",
    "\n",
    "v2 = victims_v2[[\"gender\", \"race\"]].copy()\n",
    "v2[\"incident_id\"] = victims_v2.cr_id.map(incident_id_by_cr_id)\n",
    "\n",
    "v3 = victims_v3[\n",
    "    [\"gender\", \"race\", \"injury_condition\", \"injury_description\"]\n",
    "].copy()\n",
    "v3[\"incident_id\"] = victims_v3.cr_id.map(incident_id_by_cr_id)\n",
    "add_date_of_birth(v3, victims_v3[\"birth_year\"])\n",
    "v3[\"deceased\"] = v3[\"injury_condition\"].str.match(\"deceased\", case=False)\n",
    "\n",
    "# Collect all victims in v3 as well as any in v2 that don't appear in v3\n",
    "victims = v2[~v2.incident_id.isin(v3.incident_id)].append(v3, ignore_index=True)\n",
    "check_defined(victims, \"incident_id\")\n",
    "# Specify primary keys for victims so insertion into the database is idempotent\n",
    "victims[\"id\"] = 1 + np.arange(victims.shape[0])\n",
    "\n",
    "insert_bulk_if_missing(to_dicts(victims), Victim)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be2ea7d8a1a2da86ee7a970358cba2bd7271d361dac989aabfa61f332681bfef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pdt': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
